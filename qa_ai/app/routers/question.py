from fastapi import APIRouter, UploadFile, File, Form, HTTPException, Depends
from fastapi.responses import StreamingResponse
from typing import List, Tuple
from uuid import uuid4
from pathlib import Path
import io
import zipfile
import logging
import pymysql

from app.models.question import QuestionRequest, FileResponseModel, QAResponse
from chatbot.utils.create_docx import (
    create_formatted_docx_file,
    create_simple_docx_file,
)
from ingestion.ingestion import Ingestion
from app.utils.mysql_connection import get_db
from app.security.dependency import get_current_user_id
from app.security.security import get_api_key

from chatbot.utils.file_utils import save_uploaded_file, extract_text_from_file
from chatbot.utils.validation_utils import (
    validate_request,
    get_bloom_level_name,
    # get_bloom_level_description,
    generate_bloom_assignment,
)
from chatbot.utils.db_utils import (
    deduct_token_and_log_transaction,
    insert_question_history,
)
from chatbot.utils.bloom_keywords import BLOOM_KEYWORDS
from chatbot.services.bloom_generator import BloomGenerator

from docx2pdf import convert

router = APIRouter(prefix="/questions", tags=["questions"])

TXT_DIR = Path("txt")
UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)
TXT_DIR.mkdir(exist_ok=True)


def generate_qa_content(
    segments: List[Tuple[str, str]], request: QuestionRequest
) -> QAResponse:
    bloom_assignment, segments_per_level = generate_bloom_assignment(segments, request)
    # #Ki·ªÉm tra ph√¢n b·ªï ƒëo·∫°n vƒÉn theo t·ª´ng c·∫•p ƒë·ªô
    # print("\nKI·ªÇM TRA PH√ÇN B·ªî ƒêO·∫†N VƒÇN:")
    # level_question_counts = [
    #     request.level_1,
    #     request.level_2,
    #     request.level_3,
    #     request.level_4,
    #     request.level_5,
    #     request.level_6,
    # ]
    # for i in range(6):
    #     print(
    #         f"üîπ C·∫•p ƒë·ªô {i+1}: {level_question_counts[i]} c√¢u h·ªèi ‚Üí {segments_per_level[i]} ƒëo·∫°n vƒÉn"
    #     )
    # print(f" T·ªïng ƒëo·∫°n vƒÉn: {len(segments)}")
    # print(f" T·ªïng c√¢u h·ªèi: {sum(level_question_counts)}")
    # print(f" T·ªïng ƒëo·∫°n ƒë√£ ph√¢n b·ªï: {sum(segments_per_level)}\n")

    qa_results = []
    bloom_gen = BloomGenerator(llm_name="openai")

    idx = 0
    global_question_index = 1
    for level, num_segments in enumerate(segments_per_level, start=1):
        if num_segments == 0:
            continue

        level_segments = segments[idx : idx + num_segments]
        idx += num_segments

        level_name = get_bloom_level_name(level)
        # level_desc = get_bloom_level_description(level)
        bloom_keywords = BLOOM_KEYWORDS.get(level, "")

        num_questions = getattr(request, f"level_{level}")
        segments_with_keywords = [
            (label, text, bloom_keywords, page)
            for (label, text, page) in level_segments
        ]

        qas = bloom_gen.generate_questions_for_level(
            level,
            segments_with_keywords,
            num_questions,
            level_name,
            # level_desc,
            bloom_keywords,
            start_index=global_question_index,
        )
        global_question_index += len(qas)

        answers = bloom_gen.generate_answers_for_pairs(qas)

        qa_results.append(
            {
                "level": f"C·∫•p ƒë·ªô {level} - {level_name}",
                "questions": answers,
            }
        )

    return QAResponse(
        bloom_assignment="\n".join(bloom_assignment), qa_results=qa_results
    )


@router.get("/download/zip/{file_id}", response_class=StreamingResponse)
def download_zip(file_id: str):
    """
    T·∫£i file ZIP ch·ª©a c·∫£ 2 DOCX v√† 2 PDF.
    """
    from pathlib import Path

    formatted_docx_file = TXT_DIR / f"{file_id}_formatted.docx"
    simple_docx_file = TXT_DIR / f"{file_id}_simple.docx"
    formatted_pdf_file = TXT_DIR / f"{file_id}_formatted.pdf"
    simple_pdf_file = TXT_DIR / f"{file_id}_simple.pdf"

    for file_path in [
        formatted_docx_file,
        simple_docx_file,
        formatted_pdf_file,
        simple_pdf_file,
    ]:
        if not file_path.exists():
            raise HTTPException(
                status_code=404, detail=f"File {file_path.name} kh√¥ng t·ªìn t·∫°i."
            )

    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zipf:
        zipf.write(formatted_docx_file, arcname=f"{file_id}_formatted.docx")
        zipf.write(simple_docx_file, arcname=f"{file_id}_simple.docx")
        zipf.write(formatted_pdf_file, arcname=f"{file_id}_formatted.pdf")
        zipf.write(simple_pdf_file, arcname=f"{file_id}_simple.pdf")
    zip_buffer.seek(0)

    return StreamingResponse(
        zip_buffer,
        media_type="application/zip",
        headers={"Content-Disposition": f"attachment; filename={file_id}_files.zip"},
    )


@router.post("/generate", response_model=FileResponseModel)
async def generate_questions(
    file: UploadFile = File(...),
    exam_subject: str = Form(...),
    exam_duration: str = Form(...),
    num_questions: int = Form(..., ge=1),
    level_1: int = Form(..., ge=0),
    level_2: int = Form(..., ge=0),
    level_3: int = Form(..., ge=0),
    level_4: int = Form(..., ge=0),
    level_5: int = Form(..., ge=0),
    level_6: int = Form(..., ge=0),
    api_key: str = get_api_key,
    db: pymysql.connections.Connection = Depends(get_db),
    # current_user_id: int = Depends(get_current_user_id),
):
    try:
        file_extension = file.filename.split(".")[-1].lower()
        if file_extension not in ["docx", "pdf", "txt"]:
            raise HTTPException(status_code=400, detail="Ch·ªâ h·ªó tr·ª£ docx, pdf, txt")

        request = QuestionRequest(
            num_questions=num_questions,
            level_1=level_1,
            level_2=level_2,
            level_3=level_3,
            level_4=level_4,
            level_5=level_5,
            level_6=level_6,
        )
        validate_request(request)

        file_id = str(uuid4())
        file_path = save_uploaded_file(file, file_id, UPLOAD_DIR)
        extracted_text, metadata = extract_text_from_file(file_path, file_extension)

        txt_path = TXT_DIR / f"{file_id}_extracted.txt"
        txt_path.write_text(extracted_text, encoding="utf-8")

        ingestion = Ingestion(embedding_model_name="openai")
        docs = ingestion.process_txt(str(txt_path), chunk_size=2000)

        # # Kiem tra chia ƒëoan
        # print(f"\n[T√ÅCH ƒêO·∫†N] S·ªë ƒëo·∫°n: {len(docs)}\n")
        # for i, doc in enumerate(docs, start=1):
        #     print(f"üîπ ƒêo·∫°n {i}:\n{doc.page_content}\n{'-'*60}\n")

        segments = []
        for i, doc in enumerate(docs):
            # T√¨m s·ªë trang t∆∞∆°ng ·ª©ng b·∫±ng c√°ch ki·ªÉm tra v·ªã tr√≠ vƒÉn b·∫£n
            page_number = None
            for meta in metadata:
                if doc.page_content in extracted_text:  # Ki·ªÉm tra ƒëo·∫°n vƒÉn b·∫£n
                    page_number = meta.get("page")
                    break
            segments.append((i + 1, doc.page_content, page_number))

        if not segments:
            raise HTTPException(
                status_code=400, detail="File kh√¥ng c√≥ n·ªôi dung ƒë·ªÉ x·ª≠ l√Ω."
            )

        level_counts = [level_1, level_2, level_3, level_4, level_5, level_6]
        if len(segments) < sum(1 for lv in level_counts if lv > 0):
            raise HTTPException(
                status_code=400,
                detail=f"S·ªë ƒëo·∫°n vƒÉn ({len(segments)}) kh√¥ng ƒë·ªß ƒë·ªÉ t·∫°o s·ªë c·∫•p ƒë·ªô kh√°c nhau.",
            )

        # deduct_token_and_log_transaction(db, current_user_id, cost=10)

        qa_result = generate_qa_content(segments, request)

        formatted_docx_path = TXT_DIR / f"{file_id}_formatted.docx"
        simple_docx_path = TXT_DIR / f"{file_id}_simple.docx"
        formatted_pdf_path = TXT_DIR / f"{file_id}_formatted.pdf"
        simple_pdf_path = TXT_DIR / f"{file_id}_simple.pdf"

        create_formatted_docx_file(
            qa_result, formatted_docx_path, exam_subject, exam_duration
        )
        create_simple_docx_file(
            qa_result, simple_docx_path, exam_subject, exam_duration
        )
        convert(str(formatted_docx_path), str(formatted_pdf_path))
        convert(str(simple_docx_path), str(simple_pdf_path))

        # insert_question_history(db, current_user_id, num_questions)

        return FileResponseModel(
            file_id=file_id,
            original_filename=file.filename,
            num_segments=len(segments),
            formatted_docx_download_url=f"/questions/download/formatted/{file_id}",
            simple_docx_download_url=f"/questions/download/simple/{file_id}",
            questions_and_answers=qa_result.qa_results,
        )

    except HTTPException:
        raise
    except Exception as e:
        logging.exception(f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")
        raise HTTPException(status_code=500, detail="L·ªói kh√¥ng x√°c ƒë·ªãnh")
